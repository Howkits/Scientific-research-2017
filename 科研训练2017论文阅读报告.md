

# 科研训练2017论文阅读报告

> 汪蓉. 句子级情绪分类方法研究[D]. 苏州大学, 2016.
[TOC]

---



## 1 基于整数线性规划的情感和情绪联合学习

> 单标签的句子级情绪分类问题  multi-class emotion classification
>
> 多次二分类



### 1.1 方法



- 1）首先我们分开训练情感分类器和情绪的分类器；然后将这两类分类器分别作用于同一个测试数据，分别得到初始的情感分类和情绪分类结果；
- 2）最后我们用**整数线性规划方法**作用于初始的情感分类和情绪分类结果，从而得到优化后的情感分类和情绪分类结果。为了充分利用情感分类和情绪分类任务之间的联系，我们将情感倾向和个人情绪之间的联系转化为整数线性规划方法中的一系列限制条件。

**特点：**

- 1）联合学习
- 2）不需要额外的标注数据

​	**整数线性规划方法**是一种**基于限制条件**来寻找一组**最优变量**的数学方法。具体表现为，在满足特定数量的限制条件的基础上，最小化目标损失函数（Loss Function）。

​	我们定义 $x$ 为测试样本的特征向量。由于在情感分类和情绪分类中，**文本的表示是相同的**，例如，词袋（Bag-of-words）表示，所以句子级情感分类器或句子级情绪分类器都可以对测试样本 $x$ 进行分类。

![3.3](PNG\3.3.PNG)



​	在情感分类中，测试样本被分类为情感类别，例如，正面或者负面。假设，第 $i$ 个测试样本的情感类别为 $y_i$ ，且 $y_i\in$ {0,1,2}，其中0 代表中立类别，1 代表正面类别，2 代表负面类别。为了方便使用布尔值表示结果，们进一步定义了三个不同的变量，例如，$y_{0i}\in$ {0,1}，$y_{1i}\in$ {0,1}，$y_{2i}\in$ {0,1}，分别代表了分类的结果是否为中立，正面或者负面类别。因此，第 $i$ 个测试样本的情感分类结果可以用一个向量表示，例如< $y_{0i}$,$y_{1i}$,$y_{2i}$ >。另外，基于统计学的**分类器会给出每个分类标签的预测概率**，例如：

​		$P_y$ = < $P_{y_{0i}=1}$,$P_{y_{0i}=0}$,$P_{y_{1i}=1}$,$P_{y_{1i}=0}$,$P_{y_{2i}=1}$,$P_{y_{2i}=0}$,>

​	其中， $P_{y_{0i}=1}$ 代表了第 $i$ 个测试样本的标签变量 $y_{0i}$=1 的概率。

​	相应的标签信息表示为：

​		$Y$ = < $y_{0i}$,1-$y_{0i}$,$y_{1i}$,1-$y_{1i}$,$y_{2i}$,1-$y_{2i}$ >

​	在情绪分类中，测试样本被分类为情绪类别。假设第 $i$ 个测试样本的情绪类别为 $Z_i$ ，且 $Z_i\in$ {0,1,2,3,4,5,6,7,8}，其中0-8 分别代表neutral、expect、joy、love、surprise、anxiety、sorrow、angry 和hate 等情绪类别。同样的，为了方便使用布尔值表示结果，我们定义了九种不同的变量，$z_{0i-8i}\in$ {0,1}。

​	相应的概率和标签结果表示为：

​		$P_z$ = < $P_{z_{0i}=1}$, $P_{z_{0i}=0}$,$P_{z_{1i}=1}$,$P_{z_{0i}=0}$,......,$P_{z_{8i}=1}$,$P_{z_{8i}=0}$ >

​	以及

​		$Z$ = < $z_{0i}$,1-$z_{0i}$,$z_{1i}$,1-$z_{1i}$,......$z_{8i}$,1-$z_{8i}$ >

​	基于整数线性规划的联合学习的目的是根据一系列限制条件，在使目标函数最小的前提下调整情感分类和情绪分类的结果。在本章中，我们设置的目标函数，目的是使标签结果和概率结果尽可能相似。我们使用 Cosine 方法来计算标签向量和概率向量之间的相似度。因此，我们的**目标**转化为最大化以下公式：

​		$Max\dfrac{<P_y,P_z>·<Y,Z>}{|<P_y,P_z>||<Y,Z>|}$ 

​	其中，概率向量的结果是两个初始分类器给定的，所以 |< $P_y,P_z$ >|是定值。另外，我们发现，在假设每个测试样本只有一个情感标签和一个情绪标签的前提下，|< $Y,Z$ >|也是定值。因此，我们的目标函数也转化为：

​		$Max$ < $P_y,P_z$ >·< $Y,Z$ >

​	以上问题可看作整数线性规划的问题。目标函数可以详细表示为：

$Max\sum_{k=0}^2P_{y_{ki}=1}·y_{ki}+\sum_{k=0}^2P_{y_{ki}=0}·(1-y_{ki})+\sum_{l=0}^8P_{z_{li}=1}·z_{li}+\sum_{l=0}^8P_{z_{li}=0}·(1-z_{li})$ （3.7）

​	



目标函数确定后，接下来就是设置一些列的限制条件：

（C1）整数限制：

​		$y_{ki}\in$ {0,1}以及 $z_{li}\in$ {0,1}（3.8）

（C2）单标签限制：

​		$\sum_{k=0}^2y_{ki}$ =1，and $\sum_{l=0}^8z_{li}$ =1（3.9）

（C3）中立情绪限制：

​	当测试样本在情感分类中被分类为中立时，情绪标签也必须是中立：

​		$y_{0i}$ = $z_{0i}$ （3.10）

（C4）正面情绪限制：

​	当测试样本在情感分类中被分类为正面时，情绪标签必须是集合 { joy，love，expect，surprise } 中的一个：

​		$y_{1i}$ = $Z_{1i}+Z_{2i}+Z_{3i}+Z_{4i}$ （3.11）

（C5）负面情绪限制：

​	当测试样本在情感分类中被分类为负面时，情绪标签必须是集合 { anger，anxiety，hate，sorrow } 中的一个：

​		$y_{2i}$ = $Z_{5i}+Z_{6i}+Z_{7i}+Z_{8i}$ （3.12）



### 1.2 实验



### 3.4.1 实验设置

​	在本章实验中，我们只考虑情绪主要情绪。另外，我们在原有的 8 种情绪基础上，加入了中立情绪 neutral，即当一句话不含有这 8 种情绪的任意一种情绪时，我们将此句子的情绪标签定义为 neutral。

​	实验使用的初始分类算法是基于公共工具**Mallet 工具包**的最大熵分类方法。选用每个句子的词袋特征，并且根据词的出现与否，将特征处理成布尔值向量的形式。线性规划方法，我们选用了**lp_solve5.5.2.0工具**。

​	我们从语料库中随机地选取3500 个句子作为情感分类和情绪分类共同的测试样本。然后在剩下的语料中，我们随机地选取2000、3500 和7000 个句子作为情感分类的训练样本，最后再选取另外的2000、3500 和7000 个句子作为情绪分类的训练样本。

### 3.4.2 实验结果

名称解释：

​	Single_sentiment：只使用最大熵分类器获得情感分类结果
​	Single_emotion：只使用最大熵分类器获得情绪分类结果
​	Joint_sentiment：基于整数线性规划的情感分类结果
​	Joint_emotion：基于整数线性规划的情绪分类结果

​	Baseline（基准线）：只使用最大熵分类器的分类结果
​	ILP-中立：只加入中立情绪限制的整数线性规划方法结果
​	ILP-正面：只加入正面情绪限制的整数线性规划方法结果
​	ILP-负面：只加入负面情绪限制的整数线性规划方法结果

![3.45](PNG\3.45.PNG)

​	基于整数线性规划的联合学习方法，在不同标注样本规模下的结果都优于单一的情感分类或者情绪分类。平均的，情感分类的准确率从0.635 上升到0.645，情绪分类的准确率从0.322 上升到0.335。

​	在联合学习中加入不同限制的分类性能都高于基准线的结果。其中，只加入正面情绪限制和负面情绪限制的分类性能相比基准线结果提高明显，而只加入中立情绪限制的分类性能也有一定程度的提高，但是提高的幅度较小。造成此现象的原因可能是由于样本中，中立的样本比例较小。

![3.6](PNG\3.6.PNG)





​	



## 2 基于标签关系的句子级情绪分类方法


### 4.1引言

​        本章重点研究了句子级情绪分类中的多标签分类问题。其难度远大于单标签文本分类。

> ​       常用的方法是基于标签的独立性假设，将多标签分类问题转化为多个单标签分类问题。因为这种方法忽略了标签之间的联系，所以被称为标签独立的学习方法，此方法的基本思路是针对不同的标签构建特征空间（简称特征学习）。

​       目前常用的方法存在一定的缺陷，抛弃了标签之间的联系是不符合实际情况的，不同的情绪之间是相互关联的，所以如何发现并利用多种情绪之间的联系是至关重要的。

>​        具体而言，我们根据二元关联方法，针对每个样本构造其对应每个情绪类别的伪样本，然后利用初始分类器对伪样本进行二元分类，最后根据得到的标签关系，设置相应的限制条件，并且将整数线性规划方法作用于初始的分类结果，得到优化的句子级多标签情绪分类结果。

​       这是论文给出的大致的方法，这种方法得到了不错的效果。

###4.2多标签间的依赖关系

​        论文首先给出了情绪类别中几组情绪类别共现的概率分布，从左到右共现概率不断降低。从中文情绪语料库中随机抽取100篇文章，共2751个句子。首先建立一组有限的情绪标签，对于每个句子，也就是实例，进行标注，统计任意两个情绪标签同时存在于一个句子的数量占总句子的比例，然后从大到小进行排序，以此获得两种不同情绪之间的共现概率。实际上，这个概率可能会受到抽取的语料的不同而发生变化，因此应该进行多次的抽样调查，以减小不同情绪分布而带来的影响。

​        文章中也提出了，不同情绪的句子分布并不平衡，不同句子含有标签的个数也有可能有很大差距。

### 4.3多标签情绪分类方法

#### 4.3.1基于贝叶斯网络的多标签情绪分类

>​        该方法利用贝叶斯网络直接对标签关系进行建模。贝叶斯网络中的每个节点都代表了一个标签，与此同时，网络中的连线和条件概率用来捕捉多标签之间的概率依存关系。这种方法采用了贝叶斯网络结构化学习方法，以此来确保可以找到一个与初始结构独立的全局化最优的结构。

>​        贝叶斯网络(Bayesian network)，又称信念网络(Belief Network)，或有向无环图模型(directed acyclic graphical model)，是一种概率图模型，于1985年由Judea Pearl首先提出。它是一种模拟人类推理过程中因果关系的不确定性处理模型，其网络拓扑结构是一个有向无环图(DAG)。

​        将情绪标签作为贝叶斯网络中的节点，来确定标签之间的概率关系，在这个网络中，不同的情绪标签不再是孤立的，而是和其它的标签建立了一定的关联。

> 利用最大似然估计[^footnote]来学习节点之间的条件概率。

[^footnote]: 从分布${\displaystyle D}$中抽出一个具有${\displaystyle n}$个值的采样${\displaystyle X_{1},X_{2},...,X_{n}}$，通过采样来估计参数${\displaystyle \theta}$的取值，在所有可能的${\displaystyle \theta}$取值中，寻找一个值使这个采样的”可能性“最大化。

#### 4.3.2基于标签关系的句子级情绪分类

>​        基于标签关系的句子级情绪分类方法的基本思想是利用从语料统计中总结的的标签关系以及标签数量范围约束信息来帮助多标签的句子级情绪分类。特别地，我们将标签间的关系转化为相应的限制条件，利用整数线性规划方法作用于初始的句子级情绪分类器输出结果，从而获得优化的句子级多标签情绪分类结果。

​       在情绪分类器的选择上选择了最大熵分类器，将训练语料放入最大熵模型进行训练，再作用于测试语料，得到初始结果，通过之前得到的标签关系，可以帮助得到ILP的限制条件，得到更加准确的分类结果。

>​        在该方法中，我们还使用了二元关联的方法。作为一种流行的多标签分类方法，它将每一个标签转化为二元分类的问题，得到一组独立的二元分类问题的结果。本文将二元关联作为语料的初始化步骤，我们将每个原始实例转化为K 个伪样本，其中K 是所用语料中情绪类别的总个数。

​       在多标签分类问题中，二元关联是一种问题转换方法，问题转换方法的思路是通过处理多标记训练样本，使其适应现有的学习算法，也就是将多标记学习问题转换为现有的学习问题进行求解。

​       对于每个测试样本，定义K个伪样本，通过二元分类确定样本是否包含每种情绪。

> ​        采用的中文情绪语料库来共包含8种情绪类别_joy_，_hate_，_love_，_sorrow_，_anxiety_，_surprise_，_anger_，_expect_分别表示为$\{l_1,l_2,l_3,l_4,l_5,l_6\}$ 。我们定义第$i$个样
> 本为$X_i$，$i \in D$ 其中$D$为样本空间大小，则$X^1_i$、$X^2_i$、$X^3_i$、$X^4_i$、$X^5_i$、$X^6_i$、$X^7_i$、$X^8_i$分别代表对应情绪标签的伪样本。我们将伪样本$X^j_i(1≤j≤8)$的情绪类别定义为$y^j_i$，且$y^j_i \in \{0,1\}$。当样本$X_i$含有情绪$l_j$ 时，$y^j_i=1$ ，否则，$y^j_i=0$。并且定义$y^j_i=1$时的概率为$p^1_{<i,j>}$。整数线性规划方法所用到的目标损失函数表示:
>
> $$Min \sum_{i \in D} \sum_{j \in [1,8]} (c^1_{<i,j>}y^j_i+c^0_{<i,j>}(1-y^j_i))$$ 
>
> 其中，
>
> $$c^1_{<i,j>}=-\log(p^1_{<i,j>})$$
>
> $$c^0_{<i,j>}=-\log(1-p^1_{<i,j>})$$

​     $i$表示伪样本序号，$j$表示对应情绪序号，所以$y^j_i$为二元分类的结果，$p^1_{<i,j>}$为第$i$个样本包含第$j$种情绪的概率，这个概率由条件概率得到，通过之前的对情绪的贡献统计得出。由于$p^1_{<i,j>}\in [0,1]$，取负对数后是一个非负值，由于式中$y^j_i$与$1-y^j_i$系数的存在，$c^1_{}y^j_i+c^0_{}(1-y^j_i)$得到的结果是第$i$个样本是否对第$j$种包含情绪概率的一种评估，而且使用负对数的处理也方便了之后的极大似然处理的过程。

> ​        损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。

​      之后的极大似然估计中设置的限制条件是通过开始对情绪标签共现的统计分析结果得到的。

### 4.4实验

#### 4.4.1实验设置

>​        本章所用的语料包含了从中文情绪语料库随机选取的2000 句作为测试样本，在剩下的语料中，我们随机的选取2000、4000、6000、8000 作为不同规模的训练语料。
>
>​       在特征选择上，我们采用了每个样本的词袋特征[^注]，并且将一元词的存在与否转化成二进制向量的形式。
>
>​        初始的分类算法使用了最大熵分类器的公共工具Mallet Toolkits[^1]。整数线性规划方法使用了lp_solve5.5.2.0 工具[^2]。

[^注]: 词袋模型假设一个文本或文档可以看做是一袋子单词，**不考虑**其语法和词序关系，每个词都是独立的。使用向量表示文本，词序信息已经丢失，每个文档看做一系列不相关的词的集合。
[^1]: http://mallet.cs.umass.edu/
[^2]: http://web.mit.edu/lpsolve_v5520/  (forbidden) http://web.mit.edu/lpsolve_v5520/java/docs/api/lpsolve/LpSolve.html

#### 4.4.2实验结果

​        这一节使用初始情绪分类器作为基准线，对比了基于贝叶斯网络的多标签情绪分类方法和基于标签关系的句子级情绪分类方法的优劣。评价标准使用2.4.2章节提出的标准，即从汉明损失($Hamming\ loss$)[^3]、正确率($Accuracy$)[^4]、F1值($F1-measure$)[^5]三个方面进行评价。

[^3]: 针对所有待测实例，衡量样本预测标签与样本实际标签之间的不一致程度，即样本具有某标签但未被识别出来或者不具有某标签却被误判的可能性。
[^4]: 针对所有待测实例，衡量样本的预测标签和样本实际标签之间的平均相似程度。
[^5]: F1 值用于综合评价系统的性能，即准确率和召回率的调和平均值。

​        综合评价后，论文提出的基于标签关系的句子级情绪分类方法在不同的训练样本规模下性能都优于基准线方法和LabelD方法。

​        论文之后对单个的限制条件对分类效果的影响进行了评估，发现无论是加入哪一种限制条件分类效果都比基准线的结果好，只是对分类的帮助效果不同，其中对一句话中所含的情绪个数信息对分类的结果帮助最大。

###4.5本章小结

>​        从探索文本标签关系的角度出发，研究样本的情绪标签共现情况以及单样本情绪标签数量范围约束等现象，得到情绪标签间的关系，并利用得到的关系进行多标签的句子级情绪分类。

>​        根据得到的标签关系，设置相应的标签之间的限制条件，并且通过整数线性规划方法，得到优化的句子级多标签情绪分类结果。

>​        由于句子级文本的内容长度有限，句子级文本本身存在数据稀疏的问题。在接下来的工作中，我们将重点考虑利用句子级文本上下文关系来解决这一问题。

​        由单个的独立的句子来分析情绪的劣势在于，单个的句子中含有的信息太少，很有可能出现划分错误的情况，所以需要联系上下文来对句子的情绪进行进一步的确定。





## 3 基于上下文关系的句子级情绪分类

- ##### 引言

  为了克服句子级情绪分类中数据稀疏的问题，Tkokushisa 等人提出了一种面向数据的方法来推断对话系统中句子所表达的情绪，他们从微博上收集了大量由情绪激发的事件实例来解决稀疏问题。另一方面，Xu 等人推出了一种粗粒度到细粒度的方法来进行句子级情绪分类，为了解决数据稀疏问题，他们将相邻句子的转移概率进行合并从而优化情绪分类结果。不同于标签关系和整数线性规划对情绪分类的研究，基于上下文关系的研究内容借助因子图模型将特征学习和上下文关系共同建模进行句子级的多标签情绪分类。在上下文相关信息建模的实现过程中，针对每个含有多种情绪的标签样本，构造每种情绪标签对应的伪样本，然后构建一个伪样本网络用于描述上下文之间的联系。其中，伪样本网络中的每一个节点由文本特征和上下文关系共同表示。与之前直接利用上下文关系的方法不同，该方法构建了文本特征和上下文关系联合的因子图模型，用于实现对文本特征和上下文关系的共同学习。

1. ##### 基准系统

   本章采用了目前的最好的基于上下文关系的句子级情绪分类方法[63]作为基准系统。该方法的基本思想是利用训练样本中相邻句子的相似度来进行句子级的情绪分类。首先，通过特征学习来获取训练样本中与每一句最相似的 *k* 个句子的标签集的统计概率信息。然后，利用相邻句子间的情绪标签转移概率来优化句子的情绪标签结果。

2. ##### 准备工作

   为了更好地说明我们对上下文关系建模的动机，我们系统地调查了所用预料中的上下文依赖关系。

    ![1](PNG\1.png)

   我们通过计算两个实例至少含有一个共同情绪的概率来研究上下文的依赖关系。上图显示了不同情况下，不同的两个实例含有相同情绪标签的概率。其中，“邻居”代表了两个实例为相邻的句子。“段落”代表两个实例来自同一段落。“篇章”代表两个实例来自同一篇文档。“随机”代表两个实例是随机选取的。从图中我们可以看出，来自同一上下文语境的两个实例含有相同情绪标签的概率远远大于随机的两个实例。

3. ##### 因子图模型

   ​	下面将详细介绍如何利用因子图模型对文本特征和上下文关系进行建模。

    ![2](PNG\2.png)

   ​	在这个研究中采用联合转换的方法。首先假设K为一组互斥的情绪标签集合，然后针对每种情绪类别构造样本对应的伪样本。上图给出了本文因子图模型的样本转换方法流程。其中，K含有三种情绪标签，即K={l~1,l~2,l~3}。上图可以分为三个部分：

   （1）左边的部分代表还有不同情绪标签的样本。其中每个方形代表可一个样本，每个蓝色圆圈	代表文本还有次情绪，而白色与安全代表文本不含有此情绪。

   （2）中间的部分表示伪样本网络，其中方形代表针对每种情绪类别所构造的伪样本集。椭圆代表每个样本在对应情绪类别下的温杨波，每个伪样本包含文本内容和相应的情绪标签。

   （3）右边部分表示因子图模型。该模型如下图：

   ![3](PNG\3.png)

   ​	我们将G=(V,E,X)定义为一个十里网络，其中V代表一组，E代表句子间的关系，X指句子对应文本特征向量。一个因子图有两层节点组成。所有变量的联合分布可以被分解为银子的结果。而该研究的目标就是学习联合分布来预测实例的情绪类别。其中联合分布如下：

    ![4](PNG\4.png)

   此公式包含两种因子函数：

   （1）文本特征因子函数。f(X~i^k,y~i^k)表示与每个文本X~i^k相关的传统文本特征的因子函数。此因子函数的初始化如下：

    ![5](PNG\5.png)

   （2）上下文关系因子函数。h(y~i^k,H(y~i^k))表示实例间的上下文关系，其中H(y~i^k)是和y~i^k相连接的实例集合。该函数初始化如下：

    ![6](PNG\6.png)

   其中，β~ijk是函数的权重，它代表了两个实例y~i~k和y~j~k的影响力。

4. ##### 模型学习和预测

   学习因子图模型就是估计最佳的参数配置*q* = ({*a* },{*b*}) ，用来最大化对数似然目标函数。即：

    ![7](PNG\7.png)

   接下来利用梯度下降法来优化目标函数。举例说明，我们可以根据目标函数写出每个a~kj的梯度：

    ![8](PNG\8.png)

   其中E[φ(x~ij,y~i^k)]代表特征函数φ(x~ij,y~i^k)的基于数据分布的期望，φ(x~ij,y~i^k)由数据分布给出。下图描述了学习参数α的详细算法。利用LBP方法来近似的计算边缘分布。注意点，在每次迭代过程中炫耀进行两次LBP算法。最后，根据得到的梯度和学习率η来跟新参数θ。其他参数的梯度可以类似的被推到出来。

    ![9](PNG\9.png)

   有谱了学习好的参数配置，预测任务就变成了寻找Y^U^*来优化目标函数，即：

    ![10](PNG\10.png)

   其中，Y^U^*代表测试样本中实例的情绪标签。在此，我们再一次利用LBP算法来计算每一个实例的边界概率以及预测根据最大的边界概率预测实例的标签。上诉预测是一个迭代的过程，知道结果收敛为止。

5. ##### 基于上下文关系的句子级情绪分类方法的实现

   上文介绍了方法中加入上下文关系的动机，以及详细介绍了因子图模型的因子分解过程和模型的学习和预测过程。通过构建每个实例对应于所有情绪标签的伪样本以及由这些伪样本构成的样本网络，本文使用了特征-上下文因子图（FCFG）模型进行特征学习和上下文关系的联合学习，通过对训练样本的学习实现对测试样本的多标签情绪预测。下图描述了方法实现过程。

   ![11](PNG\11.png)

- ##### 小结

  本文提出了一种基于上下文关系的句子级多标签情绪分类方法。为了解决句子级情绪分类中的数据稀疏问题，在考虑在特征学习的基础上，加入上下文关系来帮助句子级情绪分类。具体的，我们首先针对每一个含有多种情绪标签的样本，构造其在所有情绪标签下的伪样本；然后构建一个伪样本网络用于描述上下文之间的联系。最后构建依存因子图模型进行特征学习和上下文关系的联合学习，从而实现句子级的多标签情绪分类。该方法能够有效地利用上下文关系来帮助学习句子级情绪分类，并且获得了更好的分类效果。



## 4 参考文献

[1] 汪蓉.句子级情绪分类方法研究[D].苏州：苏州大学计算机科学与技术学院, 2016：36.